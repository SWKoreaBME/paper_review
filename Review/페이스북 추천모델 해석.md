# Deep Learning Recommendation Model for Personalization and Recommendation Systems

https://arxiv.org/pdf/1906.00091.pdf



딥러닝의 도래로 신경망을 기반으로 한 개인에 최적화된 추천 모델은 이 곳 페이스북을 포함하여 서비스의 생산 환경에서 중요한 도구가 되었다. 하지만 이러한 모델들은 다른 딥러닝 모델과 달리 categorical data ( 범주형 데이터 ) 를 다룬다. 그리고 이러한범주형 데이터는 higher attribute 을 표현하는데 사용된다. 이렇듯이 sparse data 에서 신경망이 효과적으로 동작하는 것은 굉장히 어려운데 특히 공개적으로 가능한 representative 모델과 데이터가 부족하다는 점은 이 분야의 연구 진전을 늦추고 있다.

이러한 배경으로 우리는 딥러닝을 기반으로 하는 추천모델을 공개하여 이 분야의 이해도를 높이려 한다. 이 모델은 페이스북에서 제공하는 오픈 소스인 pytorch 와 caffe2 로 구현이 되었다. DLRM 은 다른 모델에 Combining principles from both collaborative filtering and predictive analytics-based approaches 를 개선하여 생산 단계의 데이터에서도 작동이 잘 될 뿐만 아니라 SOTA 결과를 제공하고 있다.

이 모델의 구조와 디테일에 대한 공개는 paper 에서 확인할 수 있다. 우리는 이러한 모델을 사용하여 이 연구분야가 조금 더 활발해지고... ( 등등 좋은 말들 )



#### DLRM Model 이해하기

DLRM model 에서 **categorical features ( 범주형 feature ) 들은 embeddings 으로 처리되었으며, continuous feature 들은 bottom multilayer perceptron ( MLP ) 로 처리되었다**. 그 이후 feature 들의 second-order interactions 들은 명시적으로 (explicitly) 계산되었다. 마지막으로 결과들은 top MLP 를 통과한 후 sigmoid function 을 거쳐 click 할 확률로 출력된다. ( 영상에서 확인할 수도 있다 : https://youtu.be/DFrCEvPgEcQ)



#### Benchmarking and system co-design

DLRM 은 다음을 측정하는데 benchmark 로 사용될 수도 있다

- 모델이 구현되는 장비의 속도
- How various numerical techniques affect its accuracy

이는 BigBasin AI platform 과 같은 다른 하드웨어 플랫폼에서도 진행될 수 있다



DLRM benchmark 는 두 가지 버전의 코드를 제공하는데, 하나는 PyTorch 그리고 다른 하나는 Caffe2 이다. Glow C++ operator 에서도 작동이 가능하다. 이것을 통해 Caffe2 와 PyTorch 의 차이를 볼 수 있다. 가장 중요한 것은 각 framework 에서 최고의 feature 들을 강조하여 미래에 하나의 framework 로 통합할 수 있다는 것이다. ( single framework )

DLRM benchmark 는 random input, synthetic input 의 생성을 모두 제공한다. Many reasons to support custom generation of indices corresponding to categorical features. 예를 들어, 특정한 데이터를 사용하고 싶지만 개인정보 때문에 사용하기 어려울 때에 categorical feature 을 데이터 분포에서 추출하여 사용이 가능하다.  (*Also, if we would like to exercise system components, such as studying memory behavior, we may want to capture the fundamental locality of accesses of original trace within synthetic trace.*)

게다가, 페이스북의 추천 시스템은 경우에 따라 다양하게 사용된다. 예를 들어, 고성능을 내고 싶을 때는 input 을 batch 로 묶고 하나의 엔진에 여러모델을 동시에 배치함으로서 서로 다른 플랫폼에서 평행하게 inference 를 진행할 수 있다. 더욱이, 페이스북의 데이터 센터의 다양한 서버는 구조적인 다양성을 보이는데 SIMD 폭을 다르게 하는 것 부터 cache 의 hierarchy 를 두는 것 까지 다양하다. 구조적인 다양성 ( 차이 ) 은 추가적인 hardware-software co-design 과 최적화 기회를 제공한다. 

#### Parallelism

(생략)



#### Modeling and algorithmic experimentation

DLRM 은 python 으로 작성되어 유연한 실행을 제공한다, 모델의 구조 데이터 그리고 다른 parameter 들은 command line argument로 정의된다. DLRM 은 inference 와 train 에 모두 사용 가능하다. Training 의 경우에 backward pass operator 가 계산할 수 있는 그래프에 추가되어 parameter update 에 사용될 수 있다.

이 코드는 Kaggle Display Advertising Challenge Dataset 라는 공개 데이터를 내장하여 제공하고 있다. 이 데이터는 13개의 continuous features 와 26개의 categorical features 를 제공한다. 이것은 MLP input layer 의 크기를 정하고 또한 embedding 의 갯수를 정한다. 이 외의 다른 parameter 들은 command line 에서 정의된다. 

이 모델은 실제 데이터에서 작동하며 모델의 정확도를 측정하는데 사용된다. 특히 이는 다른 numerical techniques 이나 모델의 성능을 측정하는데도 사용할 수 있다.

